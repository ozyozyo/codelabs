
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>Build Actions with Interactive Canvas for the Google Assistant</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://storage.googleapis.com/codelab-elements/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-790299-27"></google-codelab-analytics>
  <google-codelab codelab-gaid=""
                  id="actions-with-interactive-canvas_ja"
                  title="Build Actions with Interactive Canvas for the Google Assistant"
                  environment="web"
                  feedback-link="">
    
      <google-codelab-step label="Overview" duration="2">
        <p>Actions on Googleは、スマートスピーカー、携帯電話、車、テレビ、ヘッドフォンなど、5億以上のデバイスにわたって、Googleの仮想パーソナルアシスタントである<a href="https://assistant.google.com/" target="_blank">Googleアシスタント</a>の機能を拡張するためのソフトウェアを作成できる、開発者向けプラットフォームです。ユーザーは、食料品の購入や乗車予約など、何かを達成するためにGoogleアシスタントを会話に加えることができます（現在の機能の完全なリストについては、<a href="https://assistant.google.com/explore/" target="_blank">アクションディレクトリ</a>をご覧ください）。開発者は、Actions on Googleを使用して、ユーザーとサードパーティのフルフィルメントサービスとの間の楽しく効果的な会話体験を簡単に作成し活用することができます。</p>
<p>このコードラボは、スマートディスプレイ向けのアクションを構築するための手順をカバーします。ここで構築するアクションは、スマートディスプレイが持つ画面を活用しつつ音声で操作を行うアクションです。</p>
<p>このコードラボは、Actions on Googleを使った開発に対する中級以上のレベルのコンセプトをカバーします。私たちは、このコードラボを開始する前に、<a href="https://codelabs.developers.google.com/codelabs/actions-1-ja/index.html#0" target="_blank">Level 1</a>,  <a href="https://codelabs.developers.google.com/codelabs/actions-2-ja/index.html#0" target="_blank">Level 2</a> および <a href="https://codelabs.developers.google.com/codelabs/actions-3-ja/index.html#0" target="_blank">Level 3</a> のコードラボにてカバーされるトピックについて、あなた自身で習熟しておくことをお勧めします。</p>
<h2 is-upgraded><strong>何をつくりますか？</strong></h2>
<p>このコードラボでは、以下の特徴を持つ Interactive Canvas を使ったスマートディスプレイ向けアクションを構築します。</p>
<ul>
<li>会話型アクションに対してスマートディスプレイが持つ画面を最大限活かした視覚的な情報を追加します。</li>
<li>ユーザからの音声での入力に対して、スマートディスプレイ上の画面を更新します。</li>
<li>ユーザの画面上の操作に対して、アクションに要求を送信します。</li>
</ul>
<p>このコードラボでは、じゃんけんゲームアクションを構築します。</p>
<p class="image-container"><img style="width: 602.00px" src="img/fd868f4bbd93777c.png"></p>
<p>以下のスクリーンショットは、あなたが開発するアクションでの会話フローの例を示しています。最初の画面で、ユーザはグー、チョキ、パーのどれを出すか選択します。その後、アクションが何を出すか考えている間を示す画像に切り替えます。そして、じゃんけんの結果を表示します。最後に、再び遊ぶかどうかをユーザに問い合わせます。</p>
<p class="image-container"><img style="width: 602.00px" src="img/4c69d54efbbb2daf.png"></p>
<h2 class="checklist" is-upgraded><strong>What you&#39;ll learn</strong></h2>
<ul class="checklist">
<li>会話型アクションに Interactive Canvas による視覚的な情報を追加するための方法。</li>
<li>ユーザの音声入力を受け取り、それに対して画面を更新するための方法。</li>
<li>ユーザの画面の操作を受け取り、それに対する何らかの処理をするための方法。</li>
</ul>
<h2 is-upgraded><strong>必要なもの</strong></h2>
<p>以下のツールがあなたの環境に必要となります。</p>
<ul>
<li><a href="https://www.jetbrains.com/webstorm" target="_blank">WebStorm</a>、<a href="https://atom.io/" target="_blank">Atom</a>、または <a href="https://www.sublimetext.com/" target="_blank">Sublime</a> のような、あなたが選択したIDE/テキストエディタ。</li>
<li>インストールされている NodeJS、npm、および git を含むシェルコマンドを実行するためのターミナル。</li>
<li><a href="https://www.google.com/chrome/" target="_blank">Chrome</a>のような、ウェブブラウザ。</li>
</ul>
<p>このコードラボで使われる Webhook コードを理解するために <a href="https://www.javascript.com/" target="_blank">JavaScript</a> (ES6) に精通していることを強く勧めますが、必須ではありません。</p>
<h2 is-upgraded><strong>任意: サンプルコード</strong></h2>
<p>任意ですが、私たちの <a href="https://github.com/yoichiro/rock-paper-scissors-ja" target="_blank">GitHubリポジトリ</a> から、このコードラボの全てのプロジェクトコードを得ることができます。</p>


      </google-codelab-step>
    
      <google-codelab-step label="How it works" duration="3">
        <p>Interactive Canvas は、会話型アクションをインタラクティブなウェブアプリに接続して、ユーザーが音声またはタッチでビジュアルなユーザーインターフェイスと対話できるようにする機能です。Interactive Canvas を使用するアクションには、次の4つのコンポーネントがあります。</p>
<ul>
<li><strong>会話型アクション</strong>: 会話型インターフェイスを使用してユーザーの要求を満たすアクションです。Interactive Canvasを使用するアクションは、会話型アクションと基本的に同じように機能しますが、BasicCard などのリッチレスポンスの代わりに、没入型のウェブビュー（<a href="https://developers.google.com/actions/interactivecanvas/reference/immersiveresponse" target="_blank">ImmersiveResponse</a>）を使用して応答をレンダリングします。</li>
<li><strong>ウェブアプリ</strong>: 会話中にアクションがユーザーへの応答として送信する、視覚的情報を持つフロントエンドウェブアプリです。HTML、JavaScript、CSSなどのウェブ標準技術を使って、ウェブアプリを構築します。 assistantCanvas を使用することで、ウェブアプリは会話アクションと通信できます。</li>
<li><strong>assistantCanvas</strong>: ウェブアプリと会話型アクションの間の通信を可能にするためにウェブアプリ内で使用する JavaScript API です。</li>
<li><strong>ImmersiveResponse</strong>: ウェブアプリが画面を更新する方法を定義するレスポンスタイプです。</li>
</ul>
<p>Interactive Canvasの仕組みを説明するために、Cool Colors という架空の Interactive Canvas アクションを使用して、デバイスの画面の色をユーザーが指定した色に変更する手順を紹介しましょう。ユーザーがアクションを呼び出した後、フローは次のようになります。</p>
<p class="image-container"><img style="width: 602.00px" src="img/436f5346fbb0685f.png"></p>
<ol type="1" start="1">
<li>ユーザは、アシスタントデバイス（この場合はスマートディスプレイ）に向かって、「画面を青色にして」と言います。</li>
<li>Actions on Googleプラットフォームは、インテントにマッチさせるために、ユーザの要求をDialogflowにルーティングします。</li>
<li>一致したインテントのフルフィルメントが実行され、ImmersiveResponse がスマートディスプレイに送信されます。まだロードされていない場合、デバイスはURLを使用してウェブアプリをロードします。</li>
<li>ウェブアプリがロードされた後に、assistantCanvas API を使用してコールバックを登録します。次に、ウェブアプリから登録された onUpdate コールバック関数に state 値が渡されます。この例では、フルフィルメントは、&#34;blue&#34; の値を持つ変数を含む state 値を格納した ImmersiveResponse を送信します。</li>
<li>ウェブアプリのカスタムロジックは、ImmersiveResponse の state 値を読み取り、定義済みの変更を加えます。この例では、画面を青色に変更します。 </li>
<li>assistantCanvas は、コールバックの更新を、スマートディスプレイに送信します。</li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="Install the Firebase command-line interface" duration="5">
        <p>もしあなたが既にFirebase command-line interfaceをインストールしている場合は、ここの手順を行わずに、次のセクションに進むことができます。</p>
<p>Firebase Command Line Interface (CLI) は、Cloud Functions にあなたの Actions project をデプロイ可能にします。</p>
<aside class="special"><p><strong>Tip:</strong> CLIをインストールするために、あなたは <a href="https://nodejs.org/en/" target="_blank">Node.js</a> に通常含まれる <a href="https://www.npmjs.com/" target="_blank">npm</a> をインストールする必要があります。</p>
</aside>
<p>CLIをインストールまたはアップグレードするために、以下の npm コマンドを実行してください:</p>
<pre><code>npm -g install firebase-tools</code></pre>
<aside class="warning"><p>動きませんか？ <a href="https://docs.npmjs.com/getting-started/fixing-npm-permissions" target="_blank">npm のパーミッションを変更</a>する必要があるかも知れません。</p>
</aside>
<p>CLI が正しくインストールされたかどうかを検証するために、ターミナルを開いて、以下を実行してください:</p>
<pre><code>firebase --version</code></pre>
<p>Cloud Functions の最新の機能全てが必要となるので、Firebase CLI のバージョンが <strong>3.5.0</strong> 以上かどうかを確認してください。もしそうでなければ、3.5.0 以上にアップグレードするために、 <code>npm install -g firebase-tools</code> を実行してください。</p>
<p>次のコマンドを実行して、Firebase CLI を認可します:</p>
<pre><code>firebase login</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Set up for local development" duration="10">
        <p>では、アクションの構築を始めましょう。このセクションでは、各プロジェクトの作成と準備を行います。</p>
<h2 is-upgraded><strong>Googleの権限設定を確認する</strong></h2>
<p>このコードラボで作成するアクションをテストするには、必要な権限を有効にする必要があります。</p>
<ol type="1" start="1">
<li>&#34;Activity Controls&#34; ページに行きます (<a href="https://myaccount.google.com/activitycontrols" target="_blank">https://myaccount.google.com/activitycontrols</a>)。</li>
<li>サインインされていなければ、あなたのGoogleアカウントでサインインします。</li>
<li>以下の権限を有効にします。</li>
</ol>
<ul>
<li>Web &amp; App Activity</li>
<li>Device Information</li>
<li>Voice &amp; Audio Activity</li>
</ul>
<h2 is-upgraded><strong>プロジェクトとエージェントをセットアップする</strong></h2>
<p>Actionsプロジェクトを作成し、対話に必要となる自然言語処理エンジンとしてDialogflowエージェントも準備します。まず、Actionsプロジェクトを以下の手順で作成します。</p>
<ol type="1" start="1">
<li><a href="https://console.actions.google.com/" target="_blank">Actions console</a> を開きます。</li>
<li><strong>Add/import project</strong> をクリックします。</li>
<li>&#34;rock-paper-scissors-ja&#34; のように、<strong>Project name</strong> を入力します。この名前は、あなた自身の内部参照として使われることになり、後で外部向けにプロジェクトの名前をセットすることが可能です。同時に、<strong>Choose a language for your Actions project </strong>として &#34;Japanese&#34; を、<strong>Choose your country or region</strong> として &#34;Japan&#34; を選択します。</li>
<li><strong>Create Project</strong> をクリックします。</li>
<li>画面の下にある <strong>Conversational</strong> をクリックします。</li>
</ol>
<p>Actionsプロジェクト作成後、Interactive Canvas機能を有効にします。そのために、以下の手順を行います。</p>
<ol type="1" start="1">
<li>左のナビゲーションから、<strong>Deploy &gt; Directory information</strong> をクリックします。</li>
<li><strong>Additional Information &gt; Category</strong> にて &#34;Games &amp; fun&#34; を選択します。<br><img style="width: 447.50px" src="img/3b6708c135dd475e.png"></li>
<li><strong>Interactive Canvas</strong> の &#34;Yes&#34; にチェックを入れる。<br><img style="width: 275.50px" src="img/3755f09d4d98f178.png"></li>
<li>画面上部にある <strong>Save</strong> ボタンを押す。</li>
</ol>
<p>次に、Dialogflowエージェントを以下の手順で作成します。</p>
<ol type="1" start="1">
<li>左のナビゲーションから、<strong>Build &gt; Actions</strong> をクリックします。</li>
<li><strong>Add your first Action</strong> をクリックします。</li>
<li>Create Action ダイアログ上で、<strong>Custom Intent</strong> を選択して、Dialogflow consoleを起動するために <strong>Build</strong> をクリックします。</li>
<li>Dialogflow consoleの <strong>Create Agent </strong>ページにて、<strong>DEFAULT LANGUAGE</strong> として &#34;Japanese - ja&#34; を選択した後に、<strong>Create</strong> をクリックします。</li>
</ol>
<h2 is-upgraded><strong>コードセットを生成する</strong></h2>
<p>このコードラボでは、ローカル環境にて各種コードを作成します。具体的には、フルフィルメントのコード、およびInteractive Canvasで表示されるウェブコンテンツの2つを作成します。フルフィルメントはCloud Functions for Firebaseを、ウェブコンテンツはFirebase Hostingを使って実装します。</p>
<p>では、コードセットを生成します。ターミナルを開き、以下のコマンドを実行します。</p>
<pre><code>$ mkdir rock-paper-scissors-ja
$ cd rock-paper-scissors-ja
$ firebase init</code></pre>
<p>firebaseコマンドは、いくつかの質問を尋ねてきます。以下のように回答します。</p>
<ol type="1" start="1">
<li><strong>Which Firebase CLI features do you want to set up for this folder?</strong> - Functions および Hosting を選択する。<br></li>
</ol>
<pre><code> ◯ Database: Deploy Firebase Realtime Database Rules
 ◯ Firestore: Deploy rules and create indexes for Firestore
❯◉ Functions: Configure and deploy Cloud Functions
 ◉ Hosting: Configure and deploy Firebase Hosting sites
 ◯ Storage: Deploy Cloud Storage security rules</code></pre>
<ol type="1" start="2">
<li><strong>Select a default Firebase project for this directory</strong> - Actionsプロジェクトを作成した際に、同時にGoogle Cloud Platformにプロジェクトが作成されています。ここでは、そのプロジェクトIDを選択します。もしそれとは別に新規にプロジェクトを作成したい場合は、&#34;[Create a new project]&#34; を選択してください。</li>
</ol>
<aside class="special"><p><strong>Tip:</strong> あなたの Actions project の ID は、Actions Console の <strong>Overview</strong> &gt; (Gear icon) &gt; <strong>Project settings</strong> で見つけることができます。</p>
</aside>
<ol type="1" start="3">
<li><strong>What language would you like to use to write Cloud Functions?</strong> - このコードラボでは、&#34;JavaScript&#34; を選択します。<br></li>
</ol>
<pre><code>❯ JavaScript 
  TypeScript </code></pre>
<ol type="1" start="4">
<li><strong>Do you want to use ESLint to catch probable bugs and enforce style?</strong> - &#34;N&#34; を選択します。</li>
<li><strong>Do you want to install dependencies with npm now?</strong> - &#34;Y&#34; を選択します。</li>
</ol>
<p>上記の回答がすべて完了すると、FunctionsおよびHostingのファイル群が生成され、その後に依存ライブラリのインストールが行われます。続いて、Hostingのための設定に関する質問が表示されるので、以下のように回答します、</p>
<ol type="1" start="6">
<li><strong>What do you want to use as your public directory?</strong> - &#34;public&#34; を入力します。</li>
<li><strong>Configure as a single-page app (rewrite all urls to /index.html)?</strong> - &#34;N&#34; を選択します。</li>
</ol>
<p>生成されるファイル群は、以下となります。</p>
<pre><code>├── .firebaserc
├── .gitignore
├── firebase.json
├── functions
│   ├── .gitignore
│   ├── index.js
│   ├── node_modules
│   ├── package-lock.json
│   └── package.json
└── public
    ├── 404.html
    └── index.html</code></pre>
<h2 is-upgraded><strong>依存ライブラリの追加とフルフィルメントの初期ファイルの作成</strong></h2>
<p>生成された Function のコードセットに対して、Actions on Google Client Library を依存ライブラリとして追加します。以下のコマンドを実行します。</p>
<pre><code>$ cd functions
$ npm install actions-on-google@preview --save
$ cd ..</code></pre>
<p>次に、functionsディレクトリにある index.js ファイルの内容を以下で置き換えます。</p>
<pre><code>const functions = require(&#39;firebase-functions&#39;);
const {
  dialogflow,
  ImmersiveResponse
} = require(&#39;actions-on-google&#39;);

const firebaseConfig = JSON.parse(process.env.FIREBASE_CONFIG);

const app = dialogflow({
  debug: true
});

// TODO: Write your code here.

exports.fulfillment = functions.https.onRequest(app);</code></pre>
<h2 is-upgraded><strong>フルフィルメントおよびウェブコンテンツをデプロイする</strong></h2>
<p>コードセット生成後、フルフィルメントおよびウェブコンテンツをFirebaseにデプロイします。以下の手順を行います。</p>
<pre><code>$ firebase deploy</code></pre>
<aside class="warning"><p>&#34;An unexpected error has occurred from the CLI&#34; というエラーメッセージが表示された場合は、<code>firebase deploy</code> コマンドを再度実行してみてください。</p>
</aside>
<p>数分後、あなたは Firebase にあなたの Webhook が正常にデプロイされたことを示す &#34;<strong>Deploy complete!</strong>&#34; というメッセージを見るはずです。</p>
<h2 is-upgraded><strong>デプロイメントURLの入手</strong></h2>
<p>あなたは、Cloud Functions の URL を Dialogflow に提供する必要があります。この URL を得るために、以下の手順に従ってください:</p>
<ol type="1" start="1">
<li><a href="https://console.firebase.google.com/" target="_blank">Firebase Console</a> を開きます。</li>
<li>オプションのリストから、あなたの Actions project を選択します。</li>
<li>左のナビゲーションメニューから、<strong>Develop &gt; Functions</strong> に移動します。</li>
<li><strong>Dashboard</strong> タブにて、<strong>Event</strong> の下にある &#34;fulfillment&#34; のエントリに URL があるはずです。この URL をコピーします。</li>
</ol>
<p class="image-container"><img style="width: 602.00px" src="img/2195ebecfdf6ce62.png"></p>
<h2 is-upgraded><strong>DialogflowにてURLをセットする</strong></h2>
<p>この時点で、あなたはフルフィルメントを使うために Dialogflow エージェントを更新する必要があります。そのためには、以下の手順に従います:</p>
<ol type="1" start="1">
<li><a href="https://console.dialogflow.com/" target="_blank">Dialogflow Console</a> を開きます。</li>
<li>左のナビゲーションから、<strong>Fulfillment</strong> に移動します。</li>
<li><strong>Webhook</strong> を有効にします。</li>
<li>Firebase Console からコピーした URL をペースとします。</li>
<li><strong>Save</strong> をクリックします。</li>
</ol>
<p class="image-container"><img style="width: 602.00px" src="img/c0710a5b6944d3d0.png"></p>
<h2 is-upgraded><strong>プロジェクトが正しくセットアップされたかどうかを確認する</strong></h2>
<p>この時点で、ユーザーは明示的にアクションを呼び出すことによって会話を開始できます。 Dialogflow は、ユーザからの呼び出しに応じて返事を送信し、Googleアシスタントがそれを発話します。ここで、動作確認を行います。</p>
<aside class="special"><p><strong>Tip:</strong> この<a href="https://developers.google.com/actions/tools/simulator" target="_blank">ガイド</a>では、Actions Console simulatorの利用に関する最新情報を確認できます。以下の手順を行った際に問題が発生した場合は、こちらを参照してください。</p>
</aside>
<p>Actions console simulator であなたのアクションをテストするために以下を行ってください。</p>
<ol type="1" start="1">
<li>Dialogflow Console の左のナビゲーションにて、 <strong>Integrations &gt; Google Assistant</strong> をクリックします。</li>
<li><strong>Auto-preview changes</strong> が有効になっていることを確認して、Actions project を更新するために <strong>Test</strong> をクリックします。</li>
<li>Actions Console simulator は、あなたのアクションを読み込みます。アクションをテストするために、<strong>Input</strong> フィールド内に &#34;テスト用アプリにつないで&#34; とタイプして、Enter キーを押します。</li>
<li>&#34;はい。 テスト用アプリのテストバージョンです。こんにちは！&#34; という返事を得るはずです。</li>
<li>&#34;cancel&#34; とタイプします。会話が終了します。</li>
</ol>
<p class="image-container"><img style="width: 602.00px" src="img/8ac1a2af357fed05.png"></p>
<aside class="warning"><p>このレスポンスが表示されない場合は、Firebase の設定に問題がある可能性があります。この場合は、&#34;フルフィルメントのデプロイ&#34; セクションの手順を繰り返してください。</p>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="Configure for Interactive Canvas" duration="10">
        <p>Interactive Canvasの実体は、ウェブページです。アクションがInteractive Canvasの利用をGoogleアシスタントに要求すると、スマートディスプレイやAndroidスマートフォンが持つ画面にそのウェブページが表示されます。</p>
<p>このセクションでは、Interactive Canvasを利用するために必要となる準備を行います。</p>
<h2 is-upgraded><strong>Firebase Hostingの設定を変更する</strong></h2>
<p>Interactive Canvasにてウェブページが表示される環境は、一般的なウェブブラウザと比べて特殊です。以下は、制限される項目の一部です。</p>
<ul>
<li>Cookies を利用することができません。</li>
<li>Local storage を利用することができません。</li>
<li>Geolocation を利用することができません。</li>
<li>カメラを利用することができません。</li>
<li>alert() や confirm() など、ポップアップを利用することができません。</li>
<li>Ajax のための Origin は null がセットされます。</li>
<li>メモリは 200MB 以下に制限されます。</li>
<li>アセットは null Origin からのリクエストを受け付けることが必要です。</li>
</ul>
<p>特に Origin として null が設定されているために、Firebase Hosting でウェブページを配信する際に、Access-Control-Allow-Origin レスポンスヘッダとして &#34;*&#34; を返す必要があります。また、キャッシュ機構をオフにして動的コンテンツが正しく表示されるようにすることも求められます。</p>
<p>firebase.json ファイルについて、以下の内容で置き換えます。</p>
<pre><code>{
  &#34;hosting&#34;: {
    &#34;public&#34;: &#34;public&#34;,
    &#34;ignore&#34;: [
      &#34;firebase.json&#34;,
      &#34;**/.*&#34;,
      &#34;**/node_modules/**&#34;
    ],
    &#34;headers&#34;: [
      {
        &#34;source&#34;: &#34;**&#34;,
        &#34;headers&#34;: [
          {
            &#34;key&#34;: &#34;Cache-Control&#34;,
            &#34;value&#34;: &#34;no-cache,no-store,must-revalidate&#34;
          },
          {
            &#34;key&#34;: &#34;Access-Control-Allow-Origin&#34;,
            &#34;value&#34;: &#34;*&#34;
          },
          {
            &#34;key&#34;: &#34;Access-Control-Expose-Headers&#34;,
            &#34;value&#34;: &#34;ETag&#34;
          }
        ]
      }
    ]
  }
}</code></pre>
<h2 is-upgraded><strong>ウェブページのひな型を作成する</strong></h2>
<p>ここで、Interactive Canvasで表示するウェブページの基礎となるファイルを作成します。まず、各ファイルを配置するためのディレクトリを以下のコマンドを実行することで作成します。</p>
<pre><code>$ cd public
$ mkdir css
$ mkdir images
$ mkdir js
$ cd ..</code></pre>
<h3 is-upgraded>スタイルシートの作成</h3>
<p>次に、ウェブページのデザインを定義するスタイルシートを作成します。新規に public/css/index.css ファイルを以下の内容で作成してください。</p>
<pre><code>html {
  display: flex;
  height: 100%;
}

body {
  display: flex;
  flex: 1;
  margin: 0;
  background-color: white;
  flex-direction: column;
  justify-content: center;
  align-items: center;
}

div.container {
  width: 100%;
  text-align: center;
}

#welcome {
  display: block;
}

#welcome img {
  flex: 1;
  animation: rotate-anime 3s linear infinite;
}

@keyframes rotate-anime {
  0%  {transform: rotate(0);}
  100%  {transform: rotate(360deg);}
}

#vs {
  display: none;
}

#result {
  display: none;
}

.result-row {
  display: flex;
}

.result-row div {
  flex: 1;
}

#message {
  display: none;
  font-size: 48px;
}</code></pre>
<h3 is-upgraded>HTMLファイルの作成</h3>
<p>firebase コマンドを使ってコードセットを生成した際に、すでに public/index.html ファイルが作成されています。この index.html ファイルを以下の内容で置き換えます。</p>
<pre><code>&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;meta charset=&#34;utf-8&#34; /&gt;
    &lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1&#34; /&gt;
    &lt;title&gt;じゃんけんぽん！&lt;/title&gt;
    &lt;link rel=&#34;shortcut icon&#34; type=&#34;image/x-icon&#34; href=&#34;data:image/x-icon;,&#34; /&gt;
    &lt;link rel=&#34;stylesheet&#34; href=&#34;https://www.gstatic.com/assistant/immersivecanvas/css/styles.css&#34; /&gt;
    &lt;link rel=&#34;stylesheet&#34; href=&#34;css/index.css&#34; /&gt;
    &lt;script src=&#34;https://www.gstatic.com/assistant/immersivecanvas/js/immersive_canvas_api.js&#34;&gt;&lt;/script&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div class=&#34;container&#34;&gt;
      &lt;div id=&#34;welcome&#34;&gt;
        &lt;img src=&#34;images/rock.png&#34; /&gt;
        &lt;img src=&#34;images/scissors.png&#34; /&gt;
        &lt;img src=&#34;images/paper.png&#34; /&gt;
      &lt;/div&gt;
      &lt;div id=&#34;vs&#34;&gt;
        &lt;img src=&#34;images/vs.png&#34; /&gt;
      &lt;/div&gt;
      &lt;div id=&#34;result&#34;&gt;
        &lt;div class=&#34;result-row&#34;&gt;
          &lt;div&gt;
            &lt;img id=&#34;user-choice&#34; src=&#34;&#34; /&gt;
          &lt;/div&gt;
          &lt;div&gt;
            &lt;img id=&#34;action-choice&#34; src=&#34;&#34; /&gt;
          &lt;/div&gt;
        &lt;/div&gt;
        &lt;div id=&#34;message&#34;&gt;
        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;script src=&#34;js/index.js&#34;&gt;&lt;/script&gt;
  &lt;/body&gt;
&lt;/html&gt;</code></pre>
<p>Interactive Canvas向けのウェブページは、以下を満たす必要があります。</p>
<ul>
<li>以下のスタイルシートを読み込みます。<br>https://www.gstatic.com/assistant/immersivecanvas/css/styles.css</li>
<li>以下のJavaScriptファイルを読み込みます。<br>https://www.gstatic.com/assistant/immersivecanvas/js/immersive_canvas_api.js</li>
</ul>
<p>また、レスポンシブであり、そしてSPA（Single Page Application）として作成されることが推奨されています。</p>
<p>このコードラボでは、HTMLファイルの中で主に以下の3つの構造を操作します。</p>
<ul>
<li><strong>div#welcome</strong> - ユーザがグー、チョキ、パーのどれを出すかを選択するための画面。それぞれの画像が表示される。</li>
<li><strong>div#vs</strong> - アクションが何を出すかを考えている際の画面。対決を表す画像が表示される。</li>
<li><strong>div#result</strong> - じゃんけんの結果を表示するための画面。ユーザおよびアクションがそれぞれ出した手の画像が表示されると共に、ユーザが勝ったのか、負けたのか、またはあいこだったのかを示すメッセージも表示される。</li>
</ul>
<p>会話の進行状況に応じて、上記の3つの要素のいずれかが表示されます。</p>
<h3 is-upgraded>JavaScriptファイルの作成</h3>
<p>Interactive Canvasでは、ウェブページとフルフィルメントが相互に関連しながら動作が進みます。ウェブページを動的に変更する処理は、JavaScriptファイルに記載されたコードが担当します。</p>
<p>ここで、中身のないJavaScriptファイルを作成します。public/js ディレクトリに index.js ファイルを以下の内容で作成してください。</p>
<pre><code>&#39;use strict&#39;;

// TODO: Write your code here.</code></pre>
<h3 is-upgraded>画像ファイルのダウンロード</h3>
<p>このコードラボでは、いくつかの画像ファイルを使用します。以下のURLから、画像ファイルが格納された zip ファイルをダウンロードします。</p>
<p><a href="https://www.eisbahn.jp/codelabs/actions-with-interactive-canvas/images.zip" target="_blank">画像ファイルのダウンロードリンク</a></p>
<p>そして、以下のコマンドを実行して、public/images ディレクトリに画像ファイルを配置します。</p>
<pre><code>$ cd public/images
$ unzip &lt;images.zip へのパス&gt;
$ cd ../..</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Display the Interactive Canvas" duration="10">
        <p>準備が完了したところで、いよいよ実際の開発を始めましょう。</p>
<p>このコードラボでは、じゃんけんゲームアクションを開発します。アクションが呼び出されると、アクションはユーザに対して声で「グー、チョキ、パーのどれを出しますか？」と問いかけを行います。そして、それと同時に、スマートディスプレイの画面に「グー、チョキ、パー」それぞれの画像を表示させます。ユーザは、どの手を出すか声で指示することができます。そして、画面上に表示された各画像をタップすることでも、どの手を出すか指示を行うことができるようにします。</p>
<p class="image-container"><img style="width: 602.00px" src="img/5531552b2cb55154.png"></p>
<h2 is-upgraded><strong>Default Welcome Intentを設定する</strong></h2>
<p>Dialogflowエージェントを作成すると、自動的に以下の2つのインテントが作られます。</p>
<ul>
<li><strong>Default Welcome Intent</strong> - アクションが呼び出された際のインテント。</li>
<li><strong>Default Fallback Intent</strong> - どのインテントにも認識されなかった際に呼び出されるインテント。</li>
</ul>
<p>Dialogflowエージェントの作成直後では、上記2つのインテントはフルフィルメントを使うように設定されていません。ここでは、Default Welcome Intent について、フルフィルメントを呼び出すように設定します。</p>
<p>以下の手順で、Default Welcome Intent インテントに対してフルフィルメントを有効にします。</p>
<ol type="1" start="1">
<li>Dialogflow Console の左のナビゲーションにて、 <strong>Intents</strong> をクリックします。</li>
<li>中央のインテント一覧から、<strong>Default Welcome Intent</strong> をクリックします。</li>
<li>Default Welcome Intent の設定ページの下にある <strong>Fulfillment</strong> セクションを展開し、その中にある <strong>Enable webhook call for this intent</strong> をONにします。</li>
</ol>
<p class="image-container"><img style="width: 602.00px" src="img/3d172e69568a6e13.png"></p>
<ol type="1" start="4">
<li><strong>Save</strong> ボタンを押します。</li>
</ol>
<h2 is-upgraded><strong>Default Welcome Intentインテントハンドラを実装する</strong></h2>
<p>Interactive Canvas を使ってスマートディスプレイに画面を表示するためには、Actions on Google Client Library が提供する ImmersiveResponse オブジェクトを利用します。このオブジェクトは、スマートディスプレイが持つ画面に対して、どのウェブページを表示するか、そしてユーザとのインタラクションによって会話の状況がどう変化したか、それらの情報を伝達するために使います。</p>
<p>functions/index.js ファイルの中に、以下のような行を見つけます。</p>
<pre><code>// TODO: Write your code here.</code></pre>
<p>その行の下に、以下のコードを追記します。</p>
<pre><code>app.intent(&#39;Default Welcome Intent&#39;, conv =&gt; {
  conv.ask(&#39;どの手を出しますか？グー？チョキ？それともパー？&#39;);
  conv.ask(new ImmersiveResponse({
    url: `https://${firebaseConfig.projectId}.firebaseapp.com/`
  }));
});</code></pre>
<p>最初の conv.ask() メソッド呼び出しでは、Googleアシスタントがユーザに対して問いかけるフレーズを指定しています。</p>
<p>そして、Interactive Canvas を使ってウェブページを画面に描画するために、そのウェブページのURLを持つ ImmersiveResponse オブジェクトを生成して、conv.ask() メソッドを呼び出しています。Googleアシスタントは、url プロパティに設定されたURLのウェブページをスマートディスプレイに描画します。</p>
<p>ここで指定しているURLは、Firebase Hostingにて配信されるウェブページのURLです。Actions プロジェクトのIDを process.env.FIREBASE_CONFIG から動的に取得して、URLを組み立てています。</p>
<h2 is-upgraded><strong>JavaScriptから発話を送信する</strong></h2>
<p>Interactive Canvasによってスマートディスプレイの画面に視覚的な情報を表示することができます。もしタッチ操作に対応した画面であれば、そのイベントをJavaScriptにてハンドリングすることが可能です。そして、ユーザが声で指示をしたときと同じように、ある文字列をユーザが発話したとしてGoogleアシスタントに送信することができます。</p>
<p>Interactive Canvas では、 <a href="https://developers.google.com/actions/interactivecanvas/reference/assistantcanvas" target="_blank">assistantCanvas</a> というオブジェクトが提供されます。この assistantCanvas オブジェクトの sendTextQuery() メソッドに文字列を渡すことで、Googleアシスタントにユーザフレーズが送信されます。</p>
<p>ここでは、グー、チョキ、そしてパーの3つの画像それぞれにイベントハンドラを登録します。そして、もしいずれかがタップされた際に、タップされた手を示すフレーズをGoogleアシスタントに送信する処理を追加します。</p>
<p>public/index.html ファイルの中に、以下のような &#34;welcome&#34; というID値を持つ div 要素があります。</p>
<pre><code>      &lt;div id=&#34;welcome&#34;&gt;
        &lt;img src=&#34;images/rock.png&#34; /&gt;
        &lt;img src=&#34;images/scissors.png&#34; /&gt;
        &lt;img src=&#34;images/paper.png&#34; /&gt;
      &lt;/div&gt;</code></pre>
<p>その div 要素の子要素として、3つの img 要素があります。img 要素それぞれに対して、じゃんけんの手を示す文字列を data-choice 属性として追加します。</p>
<pre><code>      &lt;div id=&#34;welcome&#34;&gt;
        &lt;img src=&#34;images/rock.png&#34; data-choice=&#34;グー&#34; /&gt;
        &lt;img src=&#34;images/scissors.png&#34; data-choice=&#34;チョキ&#34; /&gt;
        &lt;img src=&#34;images/paper.png&#34; data-choice=&#34;パー&#34; /&gt;
      &lt;/div&gt;</code></pre>
<p>次に、public/js/index.js ファイルにて、上記の各 img 要素に対してイベントハンドラを登録します。public/js/index.js ファイルの中に、以下のような記載を見つけます。</p>
<pre><code>// TODO: Write your code here.</code></pre>
<p>この下に、以下のコードを追加します。</p>
<pre><code>document.querySelectorAll(&#39;#welcome img&#39;).forEach(img =&gt; {
  img.addEventListener(&#39;click&#39;, elem =&gt; {
    assistantCanvas.sendTextQuery(elem.target.dataset.choice);
  });
});</code></pre>
<p>イベントハンドラ内では、click イベントハンドラを img 要素に追加しています。そして、タップされた対象の img 要素の dataset.choice から対応するじゃんけんの手の名称を取得しています。最後に、assistantCanvas オブジェクトの sendTextQuery() メソッドにその名称を渡すことで、ユーザがじゃんけんの手を発話したときと同じ動作をJavaScriptコードによって実行します。</p>
<h2 is-upgraded><strong>動作確認する</strong></h2>
<p>では、ここまでのコードをFirebaseにデプロイして、動作確認を行います。ターミナルから以下のコマンドを実行してください。</p>
<pre><code>$ firebase deploy</code></pre>
<aside class="warning"><p>&#34;An unexpected error has occurred from the CLI&#34; というエラーメッセージが表示された場合は、<code>firebase deploy</code> コマンドを再度実行してみてください。</p>
</aside>
<p>数分後、あなたは Firebase にあなたの Webhook が正常にデプロイされたことを示す &#34;<strong>Deploy complete!</strong>&#34; というメッセージを見るはずです。</p>
<p>次に、Actions Console Simulatorを使って、アクションを呼び出します。</p>
<aside class="special"><p><strong>Tip:</strong> この<a href="https://developers.google.com/actions/tools/simulator" target="_blank">ガイド</a>では、Actions Console simulatorの利用に関する最新情報を確認できます。以下の手順を行った際に問題が発生した場合は、こちらを参照してください。</p>
</aside>
<p>Actions console simulator であなたのアクションをテストするために以下を行ってください。</p>
<ol type="1" start="1">
<li><a href="https://console.actions.google.com/" target="_blank">Actions console</a> を開きます。</li>
<li>画面上部にて、別のプロジェクトが選択されている場合は、このコードラボで作成した Actions プロジェクトを選択します。</li>
</ol>
<p class="image-container"><img style="width: 428.69px" src="img/e3f0654d35f7e095.png"></p>
<ol type="1" start="3">
<li>左のナビゲーションから、<strong>Test &gt; Simulator</strong> をクリックします。</li>
<li>Actions Simulator の <strong>Surface</strong> 設定項目から、&#34;Smart Display&#34; をクリックします。</li>
</ol>
<p class="image-container"><img style="width: 431.50px" src="img/219a387279c2499.png"></p>
<ol type="1" start="5">
<li>アクションをテストするために、<strong>Input</strong> フィールド内に &#34;テスト用アプリにつないで&#34; とタイプして、Enter キーを押します。</li>
<li><strong>DISPLAY</strong> タブが選択されていない場合は、DISPLAY タブをクリックします。</li>
<li>グー、チョキ、パーそれぞれの画像が回転しています。これらのいずれかをクリックします。クリックした手の名称がGoogleアシスタントに発話されたことを確認します。</li>
<li>&#34;cancel&#34; とタイプします。会話が終了します。</li>
</ol>
<aside class="warning"><p>もし <strong>Surface</strong> が &#34;Speaker&#34;  の状態でアクションを呼び出した場合は、Googleアシスタントは「テスト用アプリから応答がありません。 後ほどもう一度試してください。」とエラーメッセージを返します。&#34;Smart Display&#34; もしくは &#34;Phone&#34; を選択してから、アクションを呼び出してください。 </p>
</aside>
<p class="image-container"><img style="width: 602.00px" src="img/6d8b7442ea444cdb.png"></p>
<p>この時点では、じゃんけんの手に対応するインテントが定義されていないので、Default Fallback Intent と認識されます。</p>


      </google-codelab-step>
    
      <google-codelab-step label="Update the Interactive Canvas" duration="10">
        <p>ユーザがアクションを呼び出して、じゃんけんの手を出すことができるようになりました。次に行うことは、アクションの手をランダムに決定し、ユーザが出した手と比較して、勝敗を決めます。その勝敗結果に基づいて、スマートディスプレイの画面を変更します。</p>
<p>もう少し詳しく動作を規定しておきましょう。ユーザがグー、チョキ、パーのいずれかをGoogleアシスタントに発話した後、以下の動作を行います。</p>
<ol type="1" start="1">
<li>じゃんけんのグー、チョキ、パーのいずれかが発話されたことをDialogflowが認識し、そのことをフルフィルメントに通知します。</li>
<li>フルフィルメントは、アクションの手をランダムに決定します。そして、受け取ったユーザの手と比較して、勝敗を決定します。</li>
<li>勝敗をユーザに伝えるフレーズをSimpleResponseとしてGoogleアシスタントに返します。これと同時に、ユーザが出した手、アクションが出した手、そして勝敗を示すメッセージを持つImmersiveCanvasオブジェクトを生成し、それもGoogleアシスタントに返します。</li>
<li>画面上のJavaScriptコードがフルフィルメントから返された情報を受け取ります。そして、対決を示す画像に画面を切り替えます。</li>
<li>一定時間後に、ユーザの手、アクションの手、そして勝敗を示すメッセージに画面を切り替えます。</li>
</ol>
<p class="image-container"><img style="width: 602.00px" src="img/eab6b463fd6fe393.png"></p>
<p class="image-container"><img style="width: 602.00px" src="img/c0cc5ff823b92bc4.png"></p>
<h2 is-upgraded><strong>じゃんけんの手のエンティティを定義する</strong></h2>
<p>ユーザがグー、チョキ、パーのいずれかをGoogleアシスタントに言ったことを正しく認識するために、Dialogflowエージェントにてエンティティを定義します。</p>
<p>エンティティを以下の手順で定義します。</p>
<ol type="1" start="1">
<li><a href="https://console.dialogflow.com/" target="_blank">Dialogflow Console</a> を開きます。</li>
<li>左のナビゲーションから、<strong>Entities</strong> に移動します。</li>
<li>右上にある <strong>CREATE ENTITY</strong> ボタンをクリックします。</li>
<li>Entity name として &#34;user-choice&#34; と入力します。</li>
<li><strong>Click here to edit entry</strong> をクリックします。そして、以下の入力を行います。</li>
</ol>
<ul>
<li><strong>Enter reference value</strong> に &#34;rock&#34; を入力します。</li>
<li><strong>Enter synonym</strong> に &#34;グー&#34; を入力します。</li>
</ul>
<ol type="1" start="6">
<li>同様に、以下の組み合わせで入力を行います。</li>
</ol>
<ul>
<li><strong>Enter reference value</strong>: &#34;paper&#34;<strong>、Enter synonym:</strong> &#34;パー&#34;</li>
<li><strong>Enter reference value</strong>: &#34;scissors&#34;<strong>、Enter synonym:</strong> &#34;チョキ&#34;</li>
</ul>
<ol type="1" start="7">
<li><strong>SAVE</strong> ボタンをクリックします。</li>
</ol>
<p class="image-container"><img style="width: 602.00px" src="img/b0d54347315a66fe.png"></p>
<h2 is-upgraded><strong>じゃんけんの手のインテントを定義する</strong></h2>
<p>次に、先ほど定義した user-choice エンティティを使って、ユーザからのじゃんけんの手のフレーズを識別するためのインテントを定義します。以下の手順でインテントを定義します。</p>
<ol type="1" start="1">
<li><a href="https://console.dialogflow.com/" target="_blank">Dialogflow Console</a> を開きます。</li>
<li>左のナビゲーションから、<strong>Intents</strong> に移動します。</li>
<li><strong>CREATE INTENT</strong> ボタンをクリックします。</li>
<li><strong>Intent name</strong> に &#34;Show&#34; と入力します。</li>
<li><strong>ADD TRAINING PHRASES</strong> をクリックします。そして、<strong>Add user expression</strong> に以下を入力します。</li>
</ol>
<ul>
<li>グー</li>
<li>チョキ</li>
<li>パー</li>
</ul>
<p class="image-container"><img style="width: 602.00px" src="img/2f2d18810b86d81a.png"></p>
<ol type="1" start="6">
<li><strong>Fulfillment</strong> を展開して、<strong>ENABLE FULFILLMENT</strong> をクリックします。その後、<strong>Enable webhook call for this intent</strong> にチェックを入れます。</li>
<li><strong>SAVE</strong> ボタンをクリックします。</li>
</ol>
<h2 is-upgraded><strong>Showインテントハンドラを定義する</strong></h2>
<p>DialogflowエージェントにShowインテントが定義されたことにより、ユーザがじゃんけんの手をGoogleアシスタントに言った際にフルフィルメントが呼び出されるようになりました。このセクションでは、Cloud Functions for Firebase で実装されているフルフィルメントに、Showインテントハンドラのコードを追加します。</p>
<p>まず、グー、チョキ、パーという読み方を定義するためのオブジェクト、およびユーザの手とアクションの手の組み合わせごとに勝敗のメッセージを決定するためのオブジェクトを定義します。functions/index.js ファイルの中から、以下の記載を見つけます。</p>
<pre><code>// TODO: Write your code here.</code></pre>
<p>その行の下に、以下のコードを追記します。</p>
<pre><code>const pronoun = {
  rock: &#39;グー&#39;,
  scissors: &#39;チョキ&#39;,
  paper: &#39;パー&#39;
};

const judgeMap = {
  rock: {
    rock: &#39;あいこです。&#39;,
    paper: &#39;あなたの負けです。&#39;,
    scissors: &#39;あなたの勝ちです！&#39;
  },
  paper: {
    rock: &#39;あなたの勝ちです！&#39;,
    paper: &#39;あいこです。&#39;,
    scissors: &#39;あなたの負けです。&#39;
  },
  scissors: {
    rock: &#39;あなたの負けです。&#39;,
    paper: &#39;あなたの勝ちです！&#39;,
    scissors: &#39;あいこです。&#39;
  }
};</code></pre>
<p>上記のコードに続いて、以下のShowインテントハンドラのコードについても追記します。</p>
<pre><code>app.intent(&#39;Show&#39;, (conv, param) =&gt; {
  // ユーザが出した手を取得する。
  const userChoice = param[&#39;user-choice&#39;].toLowerCase();
  // アクションの手をランダムに決定する。
  const actionChoice = [&#39;rock&#39;, &#39;paper&#39;, &#39;scissors&#39;][Math.floor(Math.random() * 3)];
  // 勝敗を示すメッセージを取得する。
  const message = judgeMap[userChoice][actionChoice];
  // SSMLを使って返事を組み立てる。
  const ssml = `
    &lt;speak&gt;
      &lt;p&gt;はい、私も何を出すか決めました。&lt;/p&gt;
      &lt;wait time=&#34;500ms&#34; /&gt;
      &lt;p&gt;では、じゃんけんぽん！&lt;/p&gt;
      &lt;wait time=&#34;400ms&#34; /&gt;
      &lt;p&gt;あなたは、${pronoun[userChoice]}を出しました。&lt;/p&gt;
      &lt;p&gt;私は、${pronoun[actionChoice]}を出しました。&lt;/p&gt;
      &lt;p&gt;${message}&lt;/p&gt;
      &lt;wait time=&#34;400ms&#34; /&gt;
      &lt;p&gt;もう一度遊びますか？&lt;/p&gt;
    &lt;/speak&gt;`;
  conv.ask(ssml);
  // 画面を更新するための情報を持つImmersiveResponseオブジェクト。
  conv.ask(new ImmersiveResponse({
    state: {
      scene: &#39;result&#39;,
      userChoice,
      actionChoice,
      message
    }
  }));
});</code></pre>
<p>Dialogflowエージェントに定義したShowインテントにより、ユーザの発話から user-choice パラメータ値が決定します（userChoice）。これを param 引数から取得し、小文字に変換します。次に、アクションの手を Math.random() を使ってランダムに決定します（actionChoice）。そして、先ほど追記した judgeMap オブジェクトを使って、勝敗を示すメッセージを決定します（message）。</p>
<p>「じゃんけんぽん！」という合図と勝敗の結果は、以下の2つの手法を使ってユーザに届けます。</p>
<ul>
<li>SSMLによる発話。</li>
<li>画面の更新。</li>
</ul>
<p><a href="https://developers.google.com/actions/reference/ssml" target="_blank">SSML</a> を使うことで、Googleアシスタントの発声をカスタマイズすることができます。このコードラボでは、wait タグを使って、文と文の発声の間に無音時間を作り出しています。</p>
<p>そして、スマートディスプレイの画面上の表示を更新するために、以下の情報を持つ ImmersiveResponse オブジェクトを生成し、conv.ask() メソッドに渡しています。</p>
<ul>
<li>scene: じゃんけん結果にシーンを移行するための &#34;result&#34; 値。</li>
<li>userChoice: ユーザが出した手を示す文字列。</li>
<li>actionChoice: アクションが出した手を示す文字列。</li>
<li>message: 勝敗を示すメッセージ文字列。</li>
</ul>
<p>SSML文字列およびImmersiveResponseオブジェクトを conv.ask() メソッドに渡すことで、Googleアシスタントに発話と画面更新を指示することができます。</p>
<h2 is-upgraded><strong>画面更新要求をハンドリングする</strong></h2>
<p>フルフィルメントから送信されたImmersiveResponseオブジェクトをGoogleアシスタントが受け取った後に、スマートディスプレイ上では画面を更新するためにJavaScriptコードが実行されます。具体的には、画面を更新する必要が生じたとき（つまり ImmersiveResponse オブジェクトがフルフィルメントから返されたとき）に呼び出されるコールバック関数を登録します。</p>
<p>public/js/index.js ファイルの中に、以下のような記載を見つけます。</p>
<pre><code>// TODO: Write your code here.</code></pre>
<p>この下に、以下のコードを追加します。</p>
<pre><code>assistantCanvas.ready({
  onUpdate(state) {
    // Display the versus image.
    if (state.scene === &#39;result&#39;) {
      document.querySelector(&#39;#welcome&#39;).style.display = &#39;none&#39;;
      document.querySelector(&#39;#vs&#39;).style.display = &#39;block&#39;;
      document.querySelector(&#39;#user-choice&#39;).src = `images/${state.userChoice}.png`;
      document.querySelector(&#39;#action-choice&#39;).src = `images/${state.actionChoice}.png`;
      document.querySelector(&#39;#message&#39;).innerText = state.message;
      // Display the result.

    }
    // Initialize the screen.

  }
});</code></pre>
<p>assistantCanvas オブジェクトの <a href="https://developers.google.com/actions/interactivecanvas/reference/assistantcanvas#ready" target="_blank">ready()</a> メソッドに対して、コールバック関数を持つオブジェクトをセットします。コールバック関数は以下の2つが定義可能です。</p>
<ul>
<li><a href="https://developers.google.com/actions/interactivecanvas/reference/assistantcanvas#onupdate" target="_blank"><strong>onUpdate()</strong></a> - state 値を持つ ImmersiveResponse オブジェクトがフルフィルメントから返されたときに呼び出される。</li>
<li><a href="https://developers.google.com/actions/interactivecanvas/reference/assistantcanvas#onttsmark" target="_blank"><strong>onTtsMark()</strong></a> - Googleアシスタントの発話の開始、終了およびSSMLに含まれる mark タグが評価されたときに呼び出される。</li>
</ul>
<aside class="warning"><p>Googleアシスタントの発話の開始時に &#34;START&#34;、終了時に &#34;END&#34; が onTtsMark() コールバック関数の引数に渡されます。SSMLの文字列に &lt;mark&gt; タグが含まれていた際に、現時点では不具合のために onTtsMark() コールバック関数が呼び出されない場合があります。 </p>
</aside>
<p>onUpdate() コールバック関数には、フルフィルメントにて ImmersiveResponse オブジェクトに渡した state オブジェクトがそのまま渡されます。ここでは、state オブジェクトに含まれる scene 値に基づいて、画面の更新処理を分岐しています。また、ユーザやアクションが出した手に応じて画像を切り替え、また勝敗を示すメッセージを表示しています。</p>
<h2 is-upgraded><strong>発話に合わせて画面を更新する</strong></h2>
<p>ここで、Googleアシスタントがじゃんけんの結果をユーザに伝える際に、発話と画面の更新タイミングにちょっとした仕掛けを入れます。具体的には、以下の動作を実現します。</p>
<ol type="1" start="1">
<li>対決を示す画面（&#34;public/images/vs.png&#34; 画像ファイルを表示する ID 値が &#34;vs&#34; の div 要素）を表示する。</li>
<li>「はい、私も何を出すか決めました。では、じゃんけんぽん！」と発話する。</li>
<li>結果を示す画面（ユーザとアクションが出した手の画像および勝敗を示すメッセージを表示する ID 値が &#34;result&#34; の div 要素）を表示する。</li>
<li>「あなたは、グーを出しました。私は、チョキを出しました。あなたの勝ちです！もう一度遊びますか？」と発話する。</li>
</ol>
<p>この動作を実現するために、JavaScript の setTimeout() 関数を利用します。</p>
<aside class="warning"><p>本来であれば、SSMLの文字列に &lt;mark&gt; タグを記載しておくことで onTtsMark()  コールバック関数が呼び出されるので、その中で div 要素の表示と非表示を切り替えるべきです。しかし、&lt;mark&gt; タグと onTtsMark() コールバック関数の動作に不具合があるため、このコードラボでは setTimeout() による実装方式を採用します。 </p>
</aside>
<p>public/js/index.js ファイルの中に、以下のような記載を見つけます。</p>
<pre><code>// Display the result.</code></pre>
<p>この下に、以下のコードを追加します。</p>
<pre><code>setTimeout(() =&gt; {
  document.querySelector(&#39;#vs&#39;).style.display = &#39;none&#39;;
  document.querySelector(&#39;#result&#39;).style.display = &#39;block&#39;;
  document.querySelector(&#39;#message&#39;).style.display = &#39;block&#39;;
}, 5000);</code></pre>
<p>上記の動作の 3. について、5秒後に行うように setTimeout() 関数に指定しています。これによって、発話と画面の動きがリッチになり、ユーザ体験が向上します。</p>
<h2 is-upgraded><strong>動作確認する</strong></h2>
<p>この時点で、遊ぶことができるようになりました。ここまでのコードをFirebaseにデプロイして、動作確認を行います。ターミナルから以下のコマンドを実行してください。</p>
<pre><code>$ firebase deploy</code></pre>
<aside class="warning"><p>&#34;An unexpected error has occurred from the CLI&#34; というエラーメッセージが表示された場合は、<code>firebase deploy</code> コマンドを再度実行してみてください。</p>
</aside>
<p>数分後、あなたは Firebase にあなたの Webhook が正常にデプロイされたことを示す &#34;<strong>Deploy complete!</strong>&#34; というメッセージを見るはずです。</p>
<p>次に、Actions Console Simulatorを使って、アクションを呼び出します。</p>
<aside class="special"><p><strong>Tip:</strong> この<a href="https://developers.google.com/actions/tools/simulator" target="_blank">ガイド</a>では、Actions Console simulatorの利用に関する最新情報を確認できます。以下の手順を行った際に問題が発生した場合は、こちらを参照してください。</p>
</aside>
<p>Actions console simulator であなたのアクションをテストするために以下を行ってください。</p>
<ol type="1" start="1">
<li><a href="https://console.actions.google.com/" target="_blank">Actions console</a> を開きます。</li>
<li>画面上部にて、別のプロジェクトが選択されている場合は、このコードラボで作成した Actions プロジェクトを選択します。</li>
</ol>
<p class="image-container"><img style="width: 428.69px" src="img/e3f0654d35f7e095.png"></p>
<ol type="1" start="3">
<li>左のナビゲーションから、<strong>Test &gt; Simulator</strong> をクリックします。</li>
<li>Actions Simulator の <strong>Surface</strong> 設定項目から、&#34;Smart Display&#34; をクリックします。</li>
</ol>
<p class="image-container"><img style="width: 431.50px" src="img/219a387279c2499.png"></p>
<ol type="1" start="5">
<li>アクションをテストするために、<strong>Input</strong> フィールド内に &#34;テスト用アプリにつないで&#34; とタイプして、Enter キーを押します。</li>
<li><strong>DISPLAY</strong> タブが選択されていない場合は、DISPLAY タブをクリックします。</li>
<li>グー、チョキ、パーそれぞれの画像が回転しています。これらのいずれかをクリックします。クリックした手の名称がGoogleアシスタントに発話されたことを確認します。</li>
<li>&#34;cancel&#34; とタイプします。会話が終了します。</li>
</ol>
<aside class="warning"><p>もし <strong>Surface</strong> が &#34;Speaker&#34;  の状態でアクションを呼び出した場合は、Googleアシスタントは「テスト用アプリから応答がありません。 後ほどもう一度試してください。」とエラーメッセージを返します。&#34;Smart Display&#34; もしくは &#34;Phone&#34; を選択してから、アクションを呼び出してください。 </p>
</aside>
<p class="image-container"><img style="width: 602.00px" src="img/a2947d67e770a78c.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="Implement remaining functions" duration="10">
        <p>ここまでで、実際にじゃんけんで遊べるようになりました。このセクションにて、最後の仕上げを行います。残る機能は、以下の2つです。</p>
<ul>
<li>もう一度遊ぶかどうかを問い合わせる。</li>
<li>いつでも終了できるようにする。</li>
</ul>
<h2 is-upgraded><strong>Follow-upインテントを追加する</strong></h2>
<p>じゃんけんの結果をユーザに伝えた後に、Googleアシスタントは再度じゃんけんをするかどうかを問い合わせています。ユーザはその問い合わせに「再度遊ぶ」のか「会話を終える」のか答えます。このような機能を実装するために、Follow-upインテントを利用すると便利です。</p>
<p>では、以下の手順にてFollow-upインテントを登録します。</p>
<ol type="1" start="1">
<li><a href="https://console.dialogflow.com/" target="_blank">Dialogflow Console</a> を開きます。</li>
<li>左のナビゲーションから、<strong>Intents</strong> に移動します。</li>
<li>&#34;Show&#34; インテントの行にマウスカーソルを合わせると、<strong>Add follow-up intent</strong> と表示されるので、それをクリックします。</li>
</ol>
<p class="image-container"><img style="width: 602.00px" src="img/47b26dce64059c57.png"></p>
<ol type="1" start="4">
<li>どの Follow-up インテントを作成するかを指定するポップアップが表示されます。この中から <strong>yes</strong> と <strong>no</strong> の2つを追加します。</li>
</ol>
<p class="image-container"><img style="width: 602.00px" src="img/276903ae940f04b2.png"></p>
<p>会話を終える意図を示す &#34;Show - no&#34; インテントについて、以下の手順で設定します。</p>
<ol type="1" start="1">
<li>左のナビゲーションから、<strong>Intents</strong> に移動します。</li>
<li>インテントの一覧から &#34;Show - no&#34; をクリックします。</li>
<li><strong>Text response</strong> に &#34;また遊びましょう。&#34; と入力します。</li>
<li><strong>Set this intent as end of conversation</strong> を ON にします。</li>
<li><strong>SAVE</strong> ボタンをクリックします。</li>
</ol>
<p class="image-container"><img style="width: 602.00px" src="img/3ceaa3003af7d940.png"></p>
<p>再びじゃんけんを行う意図を示す &#34;Show - yes&#34; インテントは、画面の更新を伴うために、フルフィルメントを呼び出します。以下の手順で &#34;Show - yes&#34; インテントの設定を行います。</p>
<ol type="1" start="1">
<li>左のナビゲーションから、<strong>Intents</strong> に移動します。</li>
<li>インテントの一覧から &#34;Show - yes&#34; をクリックします。</li>
<li><strong>Fulfillment</strong> を展開して、<strong>ENABLE FULFILLMENT</strong> をクリックします。その後、<strong>Enable webhook call for this intent</strong> にチェックを入れます。</li>
<li><strong>SAVE</strong> ボタンをクリックします。</li>
</ol>
<p>そして、Show - yes インテントハンドラを functions/index.js ファイルに追加します。functions/index.js ファイルの中から、以下の記載を見つけます。</p>
<pre><code>// TODO: Write your code here.</code></pre>
<p>その行の下に、以下のコードを追記します。</p>
<pre><code>app.intent(&#39;Show - yes&#39;, conv =&gt; {
  conv.ask(&#39;わかりました。どの手を出しますか？グー？チョキ？それともパー？&#39;);
  conv.ask(new ImmersiveResponse({
    state: {
      scene: &#39;restart&#39;
    }
  }));
});</code></pre>
<p>scene プロパティに &#34;restart&#34; を指定することで、画面の更新動作として初期状態に戻すことを指示します。</p>
<p>この ImmersiveResponse オブジェクトの内容に基づいて、画面を初期状態に戻す処理を public/js/index.js ファイルに追記します。public/js/index.js ファイルの中に、以下のような記載を見つけます。</p>
<pre><code>// Initialize the screen.</code></pre>
<p>この下に、以下のコードを追加します。</p>
<pre><code>if (state.scene === &#39;restart&#39;) {
  document.querySelector(&#39;#welcome&#39;).style.display = &#39;block&#39;;
  document.querySelector(&#39;#vs&#39;).style.display = &#39;none&#39;;
  document.querySelector(&#39;#result&#39;).style.display = &#39;none&#39;;
  document.querySelector(&#39;#message&#39;).style.display = &#39;none&#39;;
}</code></pre>
<p>ID 値として &#34;welcome&#34; を持つ div 要素のみを表示状態にすることで、画面を初期状態に戻します。</p>
<h2 is-upgraded><strong>Endインテントを追加する</strong></h2>
<p>最後に、アクションを終了するインテントを追加します。以下の手順で終了インテントを追加します。</p>
<ol type="1" start="1">
<li><a href="https://console.dialogflow.com/" target="_blank">Dialogflow Console</a> を開きます。</li>
<li>左のナビゲーションから、<strong>Intents</strong> に移動します。</li>
<li><strong>CREATE INTENT</strong> ボタンをクリックします。</li>
<li><strong>Intent name</strong> に &#34;End&#34; と入力します。</li>
<li><strong>ADD TRAINING PHRASES</strong> をクリックします。そして、<strong>Add user expression</strong> に以下のようなアクションを終えるためにユーザが言う可能性のあるフレーズを入力します。</li>
</ol>
<ol type="1" start="1">
<li>終了</li>
<li>やめる</li>
<li>バイバイ</li>
</ol>
<ol type="1" start="6">
<li><strong>Text response</strong> に &#34;また遊びましょう。&#34; と入力します。</li>
<li><strong>Set this intent as end of conversation</strong> を ON にします。</li>
<li><strong>SAVE</strong> ボタンをクリックします。</li>
</ol>
<p class="image-container"><img style="width: 602.00px" src="img/a861981cdbc3ec7b.png"></p>
<h2 is-upgraded><strong>動作確認する</strong></h2>
<p>ついにアクションが完成しました！ここまでのコードをFirebaseにデプロイして、動作確認を行います。ターミナルから以下のコマンドを実行してください。</p>
<pre><code>$ firebase deploy</code></pre>
<aside class="warning"><p>&#34;An unexpected error has occurred from the CLI&#34; というエラーメッセージが表示された場合は、<code>firebase deploy</code> コマンドを再度実行してみてください。</p>
</aside>
<p>数分後、あなたは Firebase にあなたの Webhook が正常にデプロイされたことを示す &#34;<strong>Deploy complete!</strong>&#34; というメッセージを見るはずです。</p>
<p>次に、Actions Console Simulatorを使って、アクションを呼び出します。</p>
<aside class="special"><p><strong>Tip:</strong> この<a href="https://developers.google.com/actions/tools/simulator" target="_blank">ガイド</a>では、Actions Console simulatorの利用に関する最新情報を確認できます。以下の手順を行った際に問題が発生した場合は、こちらを参照してください。</p>
</aside>
<p>Actions console simulator であなたのアクションをテストするために以下を行ってください。</p>
<ol type="1" start="1">
<li><a href="https://console.actions.google.com/" target="_blank">Actions console</a> を開きます。</li>
<li>画面上部にて、別のプロジェクトが選択されている場合は、このコードラボで作成した Actions プロジェクトを選択します。</li>
</ol>
<p class="image-container"><img style="width: 428.69px" src="img/e3f0654d35f7e095.png"></p>
<ol type="1" start="3">
<li>左のナビゲーションから、<strong>Test &gt; Simulator</strong> をクリックします。</li>
<li>Actions Simulator の <strong>Surface</strong> 設定項目から、&#34;Smart Display&#34; をクリックします。</li>
</ol>
<p class="image-container"><img style="width: 431.50px" src="img/219a387279c2499.png"></p>
<ol type="1" start="5">
<li>アクションをテストするために、<strong>Input</strong> フィールド内に &#34;テスト用アプリにつないで&#34; とタイプして、Enter キーを押します。</li>
<li><strong>DISPLAY</strong> タブが選択されていない場合は、DISPLAY タブをクリックします。</li>
<li>グー、チョキ、パーそれぞれの画像が回転しています。これらのいずれかをクリックします。クリックした手の名称がGoogleアシスタントに発話されたことを確認します。</li>
<li>&#34;はい&#34; とタイプします。再度じゃんけんが始まります。</li>
</ol>
<aside class="warning"><p>もし <strong>Surface</strong> が &#34;Speaker&#34;  の状態でアクションを呼び出した場合は、Googleアシスタントは「テスト用アプリから応答がありません。 後ほどもう一度試してください。」とエラーメッセージを返します。&#34;Smart Display&#34; もしくは &#34;Phone&#34; を選択してから、アクションを呼び出してください。 </p>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="Next steps" duration="1">
        <p><strong>おめでとうございます！</strong></p>
<p>あなたは今、Interactive Canvas を使った会話型のユーザインタフェースを構築して、スマートディスプレイ向けのアクションの構築方法を知ることができました。</p>
<h2 class="checklist" is-upgraded><strong>What we&#39;ve covered</strong></h2>
<ul class="checklist">
<li>会話型アクションに Interactive Canvas による視覚的な情報を追加するための方法。</li>
<li>ユーザの音声入力を受け取り、それに対して画面を更新するための方法。</li>
<li>ユーザの画面の操作を受け取り、それに対する何らかの処理をするための方法。</li>
</ul>
<h2 is-upgraded><strong>次は何ですか？</strong></h2>
<p>Interactive Canvasの使い方を学ぶために、Googleはよりリッチなコードサンプルを提供しています。</p>
<ul>
<li><a href="https://github.com/actions-on-google/dialogflow-interactive-canvas-nodejs" target="_blank">actions-on-google/dialogflow-interactive-canvas-nodejs</a></li>
</ul>
<p>Actions on Googleについて学ぶために、以下のリソースについても参考にすることができます:</p>
<ul>
<li><a href="http://actions.google.com/" target="_blank">actions.google.com</a>: Actions on Googleの公式ドキュメントサイトです。</li>
<li><a href="https://github.com/actions-on-google/" target="_blank">Actions on Google GitHub repo</a>: サンプルコードとライブラリがあります。</li>
<li><a href="https://dialogflow.com/" target="_blank">Dialogflow.com</a>: Dialogflowの公式ドキュメントサイトです。</li>
</ul>
<p>Twitter <a href="https://twitter.com/ActionsOnGoogle" target="_blank">@ActionsOnGoogle</a> をフォローしてください。また、あなたが開発したものを <a href="https://twitter.com/hashtag/AoGDevs?src=hash" target="_blank">#AoGDevs</a> および <a href="https://twitter.com/hashtag/AoGDevsJa?src=hash" target="_blank">#AoGDevsJa</a> にてシェアしてください。</p>
<h2 is-upgraded><strong>Feedback survey</strong></h2>
<p>次に行く前に、<a href="https://goo.gl/forms/SLcedXyVSNl7RkUc2" target="_blank">このフォーム</a>を使って私たちにフィードバックを送ってください！</p>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://storage.googleapis.com/codelab-elements/native-shim.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/custom-elements.min.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/prettify.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/codelab-elements.js"></script>

</body>
</html>
